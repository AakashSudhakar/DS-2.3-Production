{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "- How we can dump large dataset on S3 and read it by using Boto\n",
    "\n",
    "- Learn this by uploading churn dataset on S3, train a Keras DL model by `Churn_Modelling.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S3 + Boto:\n",
    "- pip install awscli (!pip install awscli on Google Colab)\n",
    "- $ aws configure (!aws configure on Google Colab)\n",
    "- AWS Access Key ID [None]: AKIAIOSFODNN7EXAMPLE\n",
    "- AWS Secret Access Key [None]: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\n",
    "- Default region name [None]: us-west-2\n",
    "- Default output format [None]: json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "\n",
    "bucket = \"makeschooldata\"\n",
    "file_name = \"data/Churn_Modelling.csv\"\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "# 's3' is a key word. create connection to S3 using default config and all buckets within S3\n",
    "\n",
    "obj = s3.get_object(Bucket=bucket, Key=file_name)\n",
    "# get object and file (key) from bucket\n",
    "\n",
    "df = pd.read_csv(obj['Body']) # 'Body' is a key word\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Prediction\n",
    "\n",
    "- Lets first read: https://medium.com/@pushkarmandot/build-your-first-deep-learning-neural-network-model-using-keras-in-python-a90b5864116d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "X = df.iloc[:, 3:13].values\n",
    "y = df.iloc[:, 13].values\n",
    "\n",
    "print(X)\n",
    "print(X.shape)\n",
    "print(y)\n",
    "\n",
    "label_encoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = label_encoder_X_1.fit_transform(X[:, 1])\n",
    "label_encoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = label_encoder_X_2.fit_transform(X[:, 2])\n",
    "print(X)\n",
    "print(X.shape)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(categorical_features=[1])\n",
    "X = one_hot_encoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:]\n",
    "# print('M:')\n",
    "# print(X[:, :10])\n",
    "# print(X[:, 10])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print(X_train.shape)\n",
    "\n",
    "classifier = Sequential()\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim=6, init='uniform', activation='relu', input_dim=11))\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim=6, init='uniform', activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim=1, init='uniform', activation='sigmoid'))\n",
    "# Compiling Neural Network\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Fitting our model\n",
    "classifier.fit(X_train, y_train, batch_size=10, nb_epoch=50, verbose=1)\n",
    "# Predicting the Test set results\n",
    "y_predict = classifier.predict(X_test)\n",
    "print(y_predict)\n",
    "y_predict = (y_predict > 0.5)\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
