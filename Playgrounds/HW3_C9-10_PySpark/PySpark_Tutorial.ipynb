{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Python Spark Regression Example\").config(\"spark.some.config.option\", \"some-value\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressionDataFrame = spark.read.csv(\"Advertising.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+---------+-----+\n",
      "|_c0|   TV|radio|newspaper|sales|\n",
      "+---+-----+-----+---------+-----+\n",
      "|  1|230.1| 37.8|     69.2| 22.1|\n",
      "|  2| 44.5| 39.3|     45.1| 10.4|\n",
      "|  3| 17.2| 45.9|     69.3|  9.3|\n",
      "|  4|151.5| 41.3|     58.5| 18.5|\n",
      "|  5|180.8| 10.8|     58.4| 12.9|\n",
      "+---+-----+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regressionDataFrame.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressionDataFrame = regressionDataFrame.drop(\"_c0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+-----+\n",
      "|   TV|radio|newspaper|sales|\n",
      "+-----+-----+---------+-----+\n",
      "|230.1| 37.8|     69.2| 22.1|\n",
      "| 44.5| 39.3|     45.1| 10.4|\n",
      "| 17.2| 45.9|     69.3|  9.3|\n",
      "|151.5| 41.3|     58.5| 18.5|\n",
      "|180.8| 10.8|     58.4| 12.9|\n",
      "+-----+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regressionDataFrame.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TV', 'radio', 'newspaper', 'sales']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionDataFrame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|(TV > 100)|count|\n",
      "+----------+-----+\n",
      "|      true|  130|\n",
      "|     false|   70|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regressionDataFrame.groupBy(regressionDataFrame.TV > 100).count().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionDataFrame.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+-----+\n",
      "|   TV|radio|newspaper|sales|\n",
      "+-----+-----+---------+-----+\n",
      "|230.1| 37.8|     69.2| 22.1|\n",
      "|151.5| 41.3|     58.5| 18.5|\n",
      "|180.8| 10.8|     58.4| 12.9|\n",
      "|120.2| 19.6|     11.6| 13.2|\n",
      "|199.8|  2.6|     21.2| 10.6|\n",
      "+-----+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regressionDataFrame.filter(regressionDataFrame.TV > 100).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|(TV > 100)|\n",
      "+----------+\n",
      "|      true|\n",
      "|     false|\n",
      "|     false|\n",
      "|      true|\n",
      "|      true|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regressionDataFrame.select(regressionDataFrame.TV > 100).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|summary|               TV|             radio|         newspaper|             sales|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|  count|              200|               200|               200|               200|\n",
      "|   mean|         147.0425|23.264000000000024|30.553999999999995|14.022500000000003|\n",
      "| stddev|85.85423631490805|14.846809176168728| 21.77862083852283| 5.217456565710477|\n",
      "|    min|              0.7|               0.0|               0.3|               1.6|\n",
      "|    max|            296.4|              49.6|             114.0|              27.0|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regressionDataFrame.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[avg(TV): double, min(TV): double, max(TV): double]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "from pyspark.sql.functions import min as psp_min\n",
    "from pyspark.sql.functions import max as psp_max\n",
    "\n",
    "regressionDataFrame.select([mean(\"TV\"), psp_min(\"TV\"), psp_max(\"TV\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanicDF = spark.read.csv(\"titanic.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----+\n",
      "|((Fare > 100) AND (Survived = 1))|count|\n",
      "+---------------------------------+-----+\n",
      "|                             true|   39|\n",
      "|                            false|  852|\n",
      "+---------------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LOGICAL_AND_STATEMENT = (titanicDF.Fare > 100) & (titanicDF.Survived == 1)\n",
    "\n",
    "titanicDF.groupBy(LOGICAL_AND_STATEMENT).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+-----+\n",
      "|(Fare > 100)|(Survived = 1)|count|\n",
      "+------------+--------------+-----+\n",
      "|        true|         false|   14|\n",
      "|        true|          true|   39|\n",
      "|       false|         false|  535|\n",
      "|       false|          true|  303|\n",
      "+------------+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LOGICAL_PARAM_1 = titanicDF.Fare > 100\n",
    "LOGICAL_PARAM_2 = titanicDF.Survived == 1\n",
    "\n",
    "titanicDF.groupBy(LOGICAL_PARAM_1, LOGICAL_PARAM_2).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+-----+\n",
      "|(Fare > 100)|(Survived = 1)|count|\n",
      "+------------+--------------+-----+\n",
      "|        true|         false|   14|\n",
      "|        true|          true|   39|\n",
      "|       false|         false|  535|\n",
      "|       false|          true|  303|\n",
      "+------------+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanicDF.groupBy(LOGICAL_PARAM_1, LOGICAL_PARAM_2).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time as t\n",
    "\n",
    "def hello_world():\n",
    "    t0 = t()\n",
    "    import sklearn\n",
    "    from sklearn.datasets import load_boston\n",
    "    print(\"hello world\")\n",
    "    t1 = t()\n",
    "    print(\"time elapsed: {:.6f}\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "time elapsed: 2.844492\n"
     ]
    }
   ],
   "source": [
    "hello_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LinearRegressionWithSGD\n",
    "from pyspark.mllib.regression import LabeledPoint as LPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressionDataRDD = regressionDataFrame.rdd.map(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[230.1, 37.8, 69.2, 22.1],\n",
       " [44.5, 39.3, 45.1, 10.4],\n",
       " [17.2, 45.9, 69.3, 9.3],\n",
       " [151.5, 41.3, 58.5, 18.5],\n",
       " [180.8, 10.8, 58.4, 12.9]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionDataRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressionDataLabeledPoints = regressionDataRDD.map(lambda data: LPoint(data[3], data[0:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(22.1, [230.1,37.8,69.2]),\n",
       " LabeledPoint(10.4, [44.5,39.3,45.1]),\n",
       " LabeledPoint(9.3, [17.2,45.9,69.3]),\n",
       " LabeledPoint(18.5, [151.5,41.3,58.5]),\n",
       " LabeledPoint(12.9, [180.8,10.8,58.4])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionDataLabeledPoints.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressionLabeledDataSplit = regressionDataLabeledPoints.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressionLabeledDataSplitTrainData, regressionLabeledDataSplitTestData = regressionLabeledDataSplit[0], regressionLabeledDataSplit[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(10.4, [44.5,39.3,45.1]),\n",
       " LabeledPoint(9.3, [17.2,45.9,69.3]),\n",
       " LabeledPoint(18.5, [151.5,41.3,58.5]),\n",
       " LabeledPoint(12.9, [180.8,10.8,58.4]),\n",
       " LabeledPoint(11.8, [57.5,32.8,23.5])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionLabeledDataSplitTrainData.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(22.1, [230.1,37.8,69.2]),\n",
       " LabeledPoint(7.2, [8.7,48.9,75.0]),\n",
       " LabeledPoint(4.8, [8.6,2.1,1.0]),\n",
       " LabeledPoint(8.6, [66.1,5.8,24.2]),\n",
       " LabeledPoint(17.4, [214.7,24.0,4.0])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionLabeledDataSplitTestData.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pyspark_LinReg(ITERATION, STEP):\n",
    "    LinRegModel = LinearRegressionWithSGD.train(data = regressionLabeledDataSplitTrainData,\n",
    "                                            iterations = ITERATION,\n",
    "                                            step = STEP,\n",
    "                                            intercept = True)\n",
    "#     return print(\"For Iteration #{} and Step Size {}, the y-Intercept is {}\".format(ITERATION, STEP, LinRegModel.intercept))\n",
    "    return LinRegModel.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Iteration #100 and Step Size 0.1, the y-Intercept is -2.0051520000778176e+263\n",
      "For Iteration #100 and Step Size 0.02, the y-Intercept is -9.899990180489119e+192\n",
      "For Iteration #100 and Step Size 0.01, the y-Intercept is -2.369054898460538e+162\n",
      "For Iteration #100 and Step Size 0.001, the y-Intercept is -3.9533446750905946e+51\n",
      "For Iteration #100 and Step Size 0.0001, the y-Intercept is 1.0013219428772064\n",
      "For Iteration #100 and Step Size 1e-05, the y-Intercept is 1.0004123211637506\n",
      "For Iteration #100 and Step Size 1e-06, the y-Intercept is 1.0000389205251445\n",
      "For Iteration #200 and Step Size 0.1, the y-Intercept is nan\n",
      "For Iteration #200 and Step Size 0.02, the y-Intercept is nan\n",
      "For Iteration #200 and Step Size 0.01, the y-Intercept is -6.706428168883327e+297\n",
      "For Iteration #200 and Step Size 0.001, the y-Intercept is -5.871989922140454e+64\n",
      "For Iteration #200 and Step Size 0.0001, the y-Intercept is 1.0013219428772064\n",
      "For Iteration #200 and Step Size 1e-05, the y-Intercept is 1.0004123211637506\n",
      "For Iteration #200 and Step Size 1e-06, the y-Intercept is 1.0000389205251445\n",
      "For Iteration #300 and Step Size 0.1, the y-Intercept is nan\n",
      "For Iteration #300 and Step Size 0.02, the y-Intercept is nan\n",
      "For Iteration #300 and Step Size 0.01, the y-Intercept is nan\n",
      "For Iteration #300 and Step Size 0.001, the y-Intercept is -9.017703496390138e+55\n",
      "For Iteration #300 and Step Size 0.0001, the y-Intercept is 1.0013219428772064\n",
      "For Iteration #300 and Step Size 1e-05, the y-Intercept is 1.0004123211637506\n",
      "For Iteration #300 and Step Size 1e-06, the y-Intercept is 1.0000389205251445\n"
     ]
    }
   ],
   "source": [
    "ALL_ITERATIONS = [100, 200, 300]\n",
    "ALL_STEPS = [0.1, 0.02, 0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "ALL_INTERCEPTS = list()\n",
    "\n",
    "for ITERATION in ALL_ITERATIONS:\n",
    "    for STEP in ALL_STEPS:\n",
    "        ALL_INTERCEPTS.append(test_pyspark_LinReg(ITERATION, STEP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating a linear regression on the top 150 companies (first one)\n",
      "Printing the coefficient and y intercept of our first 150 sales\n",
      "[0.04463628 0.18917929 0.00288182]\n",
      "2.9988647690848858\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"Advertising.csv\")\n",
    "feature_cols = [\"TV\", \"radio\", \"newspaper\"]\n",
    "\n",
    "# Use the top 150 companies to train the Linear Regression Model\n",
    "# X_train = df[feature_cols][:150]\n",
    "# Y_train = df.sales[:150]\n",
    "X, y = df[feature_cols], df.sales\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, test_size=0.25)\n",
    "\n",
    "# Instansiate the model (Linear Regression) and train it\n",
    "print(\"Generating a linear regression on the top 150 companies (first one)\")\n",
    "sales_reg = LinearRegression()\n",
    "sales_reg.fit(X_train, y_train)\n",
    "\n",
    "print(\"Printing the coefficient and y intercept of our first 150 sales\")\n",
    "print(sales_reg.coef_)\n",
    "print(sales_reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
